{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importar librerías necesarias"
      ],
      "metadata": {
        "id": "OMr7Gtvl0eD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "R_aQr-Ft0OZO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copia este archivo y coloca tus comentarios o notas en el código.\n",
        "\n",
        "Configuración de dispositivo\n",
        "\n",
        "Transformaciones de datos\n",
        "\n",
        "Cargar el conjunto de datos CIFAR-10"
      ],
      "metadata": {
        "id": "_U1gIEs80iXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=4, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N52Oby640RHj",
        "outputId": "af1f2f97-e6f6-43f3-fa1c-baecea4bc53f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:12<00:00, 13.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definición de la CNN"
      ],
      "metadata": {
        "id": "cn-4uHS15D_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "gZTpM14i0WBj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicialización del modelo, criterio y optimizador"
      ],
      "metadata": {
        "id": "BLNEGr1E5KTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net().to(device)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "0rAvQX3G0rXZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "edH_BJmN5PUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "num_epochs = 5\n",
        "\n",
        "print(\"--- Training Started ---\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(images)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(trainloader.dataset)\n",
        "    train_losses.append(epoch_loss)\n",
        "\n",
        "    net.eval()\n",
        "    running_val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = net(images)\n",
        "            val_loss = loss_function(outputs, labels)\n",
        "            running_val_loss += val_loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    epoch_val_loss = running_val_loss / len(testloader.dataset)\n",
        "    val_losses.append(epoch_val_loss)\n",
        "\n",
        "    epoch_accuracy = 100.0 * correct / total\n",
        "    val_accuracies.append(epoch_accuracy)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Val Loss: {epoch_val_loss:.4f}, Val Accuracy: {epoch_accuracy:.2f}%\")\n",
        "\n",
        "print(\"--- Finished Training ---\")\n",
        "\n",
        "metrics = [train_losses, val_losses, val_accuracies]\n",
        "print(metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkMH9b8_5yTM",
        "outputId": "236d6227-957d-4b0e-af8a-acb6febe98e5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training Started ---\n",
            "Epoch [1/5], Train Loss: 1.6438, Val Loss: 1.2939, Val Accuracy: 54.61%\n",
            "Epoch [2/5], Train Loss: 1.1909, Val Loss: 1.0344, Val Accuracy: 63.96%\n",
            "Epoch [3/5], Train Loss: 1.0074, Val Loss: 0.9435, Val Accuracy: 67.25%\n",
            "Epoch [4/5], Train Loss: 0.8883, Val Loss: 0.9181, Val Accuracy: 68.78%\n",
            "Epoch [5/5], Train Loss: 0.8002, Val Loss: 0.8943, Val Accuracy: 69.67%\n",
            "--- Finished Training ---\n",
            "[[1.643791798388958, 1.1908757510781287, 1.0073684884829446, 0.8882555445211008, 0.8002155720828846], [1.293865408271551, 1.0344316519215704, 0.9434914861878381, 0.9181440514506772, 0.8942551290688104], [54.61, 63.96, 67.25, 68.78, 69.67]]\n"
          ]
        }
      ]
    }
  ]
}